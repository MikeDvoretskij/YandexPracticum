{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\"6_class.csv\")\n",
    "except:\n",
    "    data = pd.read_csv(\"/datasets/6_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"Temperature (K)\"])\n",
    "plt.title(\"Temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"Luminosity(L/Lo)\"])\n",
    "plt.title(\"Light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"Radius(R/Ro)\"])\n",
    "plt.title(\"Radius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"Absolute magnitude(Mv)\"])\n",
    "plt.title(\"Magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns = [\"Star color\"]\n",
    "numeric_columns = [\"Luminosity(L/Lo)\", \"Radius(R/Ro)\", \"Absolute magnitude(Mv)\", \"Star type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[category_columns[0]] = data[category_columns[0]].apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[category_columns[0]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = {\n",
    "    'blue white':'blue-white',\n",
    "    'white-yellow': 'yellow-white', \n",
    "}\n",
    "data[category_columns[0]] = data[category_columns[0]].apply(lambda x: color[x] if x in color else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop([\"Temperature (K)\"], axis=1)\n",
    "target = data[\"Temperature (K)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                    random_state=12345, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore', drop=\"first\", sparse=False)\n",
    "ohe.fit(X_train[category_columns])\n",
    "X_train_ohe = ohe.transform(X_train[category_columns])\n",
    "X_train_ohe = pd.DataFrame(X_train_ohe, columns=ohe.get_feature_names_out(), index=X_train.index)\n",
    "X_train = X_train.drop(category_columns, axis=1)\n",
    "X_train = X_train.join(X_train_ohe)\n",
    "\n",
    "X_test_ohe = ohe.transform(X_test[category_columns])\n",
    "X_test_ohe = pd.DataFrame(X_test_ohe, columns=ohe.get_feature_names_out(), index=X_test.index)\n",
    "X_test = X_test.drop(category_columns, axis=1)\n",
    "X_test = X_test.join(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(\"Unnamed: 0\", axis=1)\n",
    "X_train = X_train.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
    "X_test[numeric_columns]= scaler.transform(X_test[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 12345\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values, device=device)\n",
    "X_test = torch.tensor(X_test.values, device=device)\n",
    "y_train = torch.tensor(y_train.values, device=device, dtype=torch.float64)\n",
    "y_test = torch.tensor(y_test.values, device=device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neruons = X_train.shape[1]\n",
    "output_neruons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.LeakyReLU(0.2)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.LeakyReLU(0.2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Baseline(input_neruons, input_neruons//2, input_neruons//2, output_neruons).to(dtype=torch.float64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(base_model.parameters(), lr=1e-3)\n",
    " \n",
    "loss = nn.MSELoss().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    " \n",
    "num_epochs = 1000\n",
    " \n",
    "num_batches = ceil(len(X_train)/batch_size)\n",
    "\n",
    "accs = []\n",
    "epoch_ = []\n",
    " \n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    order = np.random.permutation(len(X_train))\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_index = batch_idx * batch_size\n",
    "        optimizer.zero_grad()\n",
    "  \n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "        X_batch = X_train[batch_indexes]\n",
    "        y_batch = y_train[batch_indexes]\n",
    "  \n",
    "        preds = base_model(X_batch).flatten()\n",
    "            \n",
    "        loss_value = loss(preds, y_batch)\n",
    " \n",
    "        loss_value.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "        base_model.eval()\n",
    "        test_preds = base_model(X_test)\n",
    "        accuracy = mean_squared_error(test_preds.to(\"cpu\").detach().numpy(), y_test.to(\"cpu\").detach().numpy(), squared=False)\n",
    "        accs.append(accuracy)\n",
    "        epoch_.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_, accs)\n",
    "plt.title(\"RMSELoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([i[0] for i in base_model(X_test).to(\"cpu\").detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [i for i in range(len(preds) // 2)]\n",
    "true_values = y_test.to(\"cpu\").numpy()[:len(preds) // 2]\n",
    "predictions = preds[:len(preds) // 2]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "plt.bar(x, true_values, 0.4, label='True Values', color='blue')\n",
    "\n",
    "plt.bar(x, predictions, 0.35, label='Predictions', color='red', alpha=0.8)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE = {mean_squared_error(preds, y_test.to('cpu').numpy(), squared=False):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_nn(params: dict, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
    "    input_neurons = params.get(\"input_neurons\", X_train.shape[1])\n",
    "    output_neurons = params.get(\"output_neurons\", 1)\n",
    "    n_combinated_layers = params.get(\"n_combinated_layers\", 5)\n",
    "    function_activation = params.get(\"function_activation\", nn.LeakyReLU(0.2))\n",
    "    drop_out_every_layer = params.get(\"drop_out_every_layer\", 3)\n",
    "    drop_out_part = params.get(\"drop_out_part\", 0.25)\n",
    "    num_epochs = params.get(\"num_epochs\", 1000)\n",
    "    batch_size = params.get(\"batch_size\", 10)\n",
    "    device = params.get(\"device\", \"cuda\")\n",
    "    rmse_ = params.get(\"rmse_\", 10**100)\n",
    "    middle_layers = params.get(\"middle_layers\")\n",
    "    \n",
    "    n_neruons = [input_neurons]\n",
    "\n",
    "    for i in range(n_combinated_layers):\n",
    "        for g in middle_layers:\n",
    "            n_neruons.append(g)\n",
    "    n_neruons.append(output_neurons)\n",
    "\n",
    "    net_layers = []\n",
    "\n",
    "    for i in range(1, len(n_neruons) - 1):\n",
    "        if i == 1 or i % drop_out_every_layer != 0:\n",
    "            net_layers.append(nn.Linear(n_neruons[i - 1], n_neruons[i]))\n",
    "            net_layers.append(function_activation)   \n",
    "        else:\n",
    "            net_layers.append(nn.Dropout(drop_out_part))\n",
    "            net_layers.append(nn.Linear(n_neruons[i - 1], n_neruons[i]))\n",
    "            net_layers.append(function_activation)\n",
    "\n",
    "    net_layers.append(nn.Linear(n_neruons[-2], n_neruons[-1]))\n",
    "\n",
    "    net = nn.Sequential(*net_layers).to(dtype=torch.float64, device=device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    loss = nn.MSELoss().to(device=device)\n",
    "\n",
    "    num_batches = ceil(len(X_train)/batch_size)\n",
    "\n",
    "    best_rmse = rmse_\n",
    "    best_optimizer = None\n",
    "    best_net = None\n",
    "\n",
    "    # training_model\n",
    "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_index = batch_idx * batch_size\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_indexes = order[start_index:start_index+batch_size]\n",
    "            X_batch = X_train[batch_indexes]\n",
    "            y_batch = y_train[batch_indexes]\n",
    "\n",
    "            preds = net(X_batch).flatten()\n",
    "                \n",
    "            loss_value = loss(preds, y_batch)\n",
    "\n",
    "            loss_value.backward()\n",
    "                \n",
    "            optimizer.step()\n",
    "                \n",
    "            if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "                net.eval()\n",
    "                test_preds = net(X_test)\n",
    "                rmse = mean_squared_error(test_preds.to(\"cpu\").detach().numpy(), y_test.to(\"cpu\").detach().numpy(), squared=False)\n",
    "\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_optimizer = optimizer\n",
    "                    best_net = net\n",
    "                    \n",
    "\n",
    "    return best_net, best_optimizer, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(params):\n",
    "    param_names = list(params.keys())\n",
    "    param_values = [params[param_name] for param_name in param_names]\n",
    "\n",
    "    param_combinations = list(itertools.product(*param_values))\n",
    "\n",
    "    for combination in param_combinations:\n",
    "        params_for_net = {param_names[i]: combination[i] for i in range(len(param_names))}\n",
    "        yield params_for_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"middle_layers\":[[input_neruons//2, input_neruons//2, input_neruons],\n",
    "                     [input_neruons//3, input_neruons//3, input_neruons//2]],\n",
    "    \"n_combinated_layers\":[1, 5, 10],\n",
    "    \"num_epochs\":[1000, 2000, 3000],\n",
    "    \"batch_size\":[20, 30, 40], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1\n",
    "\n",
    "for i in params:\n",
    "    iterations *= len(params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = cross_validate(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = None\n",
    "best_rmse = 10 ** 100\n",
    "best_model = None\n",
    "best_optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iterations):\n",
    "    param = next(params)\n",
    "    net, optimizer, rmse = custom_nn(param)\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_params = param\n",
    "        best_model = net\n",
    "        best_optimizer = optimizer\n",
    "        print(best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neruons = [14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for g in [7, 7, 14]:\n",
    "        n_neruons.append(g)\n",
    "n_neruons.append(output_neruons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_layers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(n_neruons) - 1):\n",
    "    if i == 1 or i % 3 != 0:\n",
    "        net_layers.append(nn.Linear(n_neruons[i - 1], n_neruons[i]))\n",
    "        net_layers.append(nn.LeakyReLU(0.2))   \n",
    "    else:\n",
    "        net_layers.append(nn.Dropout(0.25))\n",
    "        net_layers.append(nn.Linear(n_neruons[i - 1], n_neruons[i]))\n",
    "        net_layers.append(nn.LeakyReLU(0.2))\n",
    "\n",
    "net_layers.append(nn.Linear(n_neruons[-2], n_neruons[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(*net_layers).to(dtype=torch.float64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    " \n",
    "loss = nn.MSELoss().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    " \n",
    "num_epochs = 3000\n",
    " \n",
    "num_batches = ceil(len(X_train)/batch_size)\n",
    "\n",
    "accs = []\n",
    "epoch_ = []\n",
    "\n",
    "best_rmse = 10**100\n",
    "best_optimizer = None\n",
    "best_net = None\n",
    "\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_index = batch_idx * batch_size\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "        X_batch = X_train[batch_indexes]\n",
    "        y_batch = y_train[batch_indexes]\n",
    "\n",
    "        preds = net(X_batch).flatten()\n",
    "            \n",
    "        loss_value = loss(preds, y_batch)\n",
    "\n",
    "        loss_value.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "        net.eval()\n",
    "        test_preds = net(X_test)\n",
    "        rmse = mean_squared_error(test_preds.to(\"cpu\").detach().numpy(), y_test.to(\"cpu\").detach().numpy(), squared=False)\n",
    "        accs.append(rmse)\n",
    "        epoch_.append(epoch)\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_optimizer = optimizer\n",
    "            best_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_, accs)\n",
    "plt.title(\"RMSELoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([i[0] for i in net(X_test).to(\"cpu\").detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [i for i in range(len(preds) // 2)]\n",
    "true_values = y_test.to(\"cpu\").numpy()[:len(preds) // 2]\n",
    "predictions = preds[:len(preds) // 2]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "plt.bar(x, true_values, 0.4, label='True Values', color='blue')\n",
    "\n",
    "plt.bar(x, predictions, 0.35, label='Predictions', color='red', alpha=0.8)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE = {mean_squared_error(preds, y_test.to('cpu').numpy(), squared=False):0.2f}\")"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4943,
    "start_time": "2023-10-17T16:24:08.737Z"
   },
   {
    "duration": 230,
    "start_time": "2023-10-17T16:24:13.683Z"
   },
   {
    "duration": 102,
    "start_time": "2023-10-17T16:24:22.122Z"
   },
   {
    "duration": 125,
    "start_time": "2023-10-17T16:24:23.844Z"
   },
   {
    "duration": 1974,
    "start_time": "2023-10-23T18:48:53.501Z"
   },
   {
    "duration": 140,
    "start_time": "2023-10-23T18:48:55.476Z"
   },
   {
    "duration": 74,
    "start_time": "2023-10-23T18:48:55.618Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-23T18:48:55.693Z"
   },
   {
    "duration": 20,
    "start_time": "2023-10-23T18:48:55.706Z"
   },
   {
    "duration": 126,
    "start_time": "2023-10-23T18:48:55.818Z"
   },
   {
    "duration": 112,
    "start_time": "2023-10-23T18:48:56.053Z"
   },
   {
    "duration": 146,
    "start_time": "2023-10-23T18:48:56.246Z"
   },
   {
    "duration": 132,
    "start_time": "2023-10-23T18:48:56.458Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-23T18:48:56.959Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-23T18:48:57.200Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-23T18:48:57.588Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-23T18:48:57.989Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-23T18:48:58.421Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-23T18:48:58.901Z"
   },
   {
    "duration": 156,
    "start_time": "2023-10-23T18:48:59.298Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-23T18:48:59.553Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-23T18:48:59.769Z"
   },
   {
    "duration": 15,
    "start_time": "2023-10-23T18:48:59.961Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-23T18:49:00.995Z"
   },
   {
    "duration": 25,
    "start_time": "2023-10-23T18:49:01.212Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-23T18:49:01.489Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-23T18:49:14.182Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-23T18:49:14.681Z"
   },
   {
    "duration": 2,
    "start_time": "2023-10-23T18:49:15.171Z"
   },
   {
    "duration": 17,
    "start_time": "2023-10-23T18:49:15.799Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
